{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlYxWinIz3e2"
      },
      "source": [
        "# Synteza Tacotron2\n",
        "\n",
        "**Właściciel tego notatnika: Tadejro**\n",
        "\n",
        "Link do oryginalnego notatnika: https://colab.research.google.com/drive/1HLtvXS1X1mChiXHM02myLz3SUhzJ4bqx\n",
        "\n",
        "Link do źródła w repozytorium: https://github.com/8tm/mekatron-files/blob/master/colab_notepads/tacotron2/tacotron2_synthesis.ipynb\n",
        "\n",
        "Połączenie wszystkiego, co do tej pory powstało na Mekatronie. Podziękowania dla:\n",
        "- Meka\n",
        "- Adam is cool and stuff – za orginalną wersję tacotronową\n",
        "- Heroba – za zrobienie wersji z formularzami (Link: https://colab.research.google.com/drive/1FXQRoCRl4NW1DY77HiRcIySjrjS-wfSb)\n",
        "- Patryka – za funkcję \"zagraniczny_głos\" i naprawienie pobierania z dysków Google\n",
        "- Vojaka – za oryginalną wersję tego notatnika\n",
        "- Patryk025 - za poprawki w hifi-gan i jeszcze kilka rzeczy\n",
        "\n",
        "Obecnie notatnik posiada drobny błąd – przy pierwszej syntezie po uruchomieniu tego Colaba skrypt \"zagraniczny_głos\" nie załapuje, więc trzeba jeszcze raz wygenerować. Wszystkie kolejne generacje są już OK. Jak ktoś zna się na programowaniu, to może pomóc mi w naprawie tego błędu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEhRJrnA3Tbf"
      },
      "source": [
        "# Krok 1: Sprawdzenie karty graficznej"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccUtkE7O0vfk"
      },
      "outputs": [],
      "source": [
        "#@title # Informacje o karcie graficznej i wersję pythona\n",
        "_, card = !nvidia-smi --query-gpu=gpu_name --format='csv'\n",
        "print(card)\n",
        "!python -V"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Instalacja paczek\n",
        "%%sh\n",
        "echo \"Packages for Python 3.10.12\"\n",
        "# Packages required for training and for synthesis\n",
        "pip install -q \\\n",
        "    gdown==4.7.1 \\\n",
        "    unidecode==1.3.6 \\\n",
        "    tensorboardX==2.6.1 \\\n",
        "    pyunpack==0.3 \\\n",
        "    patool==1.12 \\\n",
        "    pynvml==11.5.0 \\\n",
        "    librosa==0.10.0-2 \\\n",
        "    pydub==0.25.1 \\\n",
        "    ffmpeg==1.4\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_yPSqAlHsgdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWnEz_rE0flo"
      },
      "source": [
        "# Krok 2: Import bibliotek, załadowanie własnych funkcji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uW7z54Z1yC5"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#Instalacja Tacotrona i Waveglow\n",
        "\n",
        "import glob\n",
        "import locale\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import torch\n",
        "\n",
        "import gdown\n",
        "import matplotlib\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import IPython.display as ipd\n",
        "import scipy.io.wavfile\n",
        "from pydub import AudioSegment\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "\n",
        "def git_clone(url):\n",
        "    project_name = os.path.splitext(os.path.basename(url))[0]\n",
        "    if not os.path.exists(project_name):\n",
        "        !git clone -q --recursive {url}\n",
        "    return project_name\n",
        "\n",
        "\n",
        "project_name = git_clone('https://github.com/8tm/mekatron2.git')\n",
        "\n",
        "sys.path.append(os.path.join(project_name, 'waveglow/'))\n",
        "sys.path.append(project_name)\n",
        "\n",
        "from hparams import create_hparams\n",
        "from model import Tacotron2\n",
        "from layers import TacotronSTFT\n",
        "from audio_processing import griffin_lim\n",
        "from text import text_to_sequence\n",
        "from denoiser import Denoiser\n",
        "\n",
        "\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "\n",
        "def plot_data(data, figsize=(9, 4)):\n",
        "    %matplotlib inline\n",
        "    fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
        "    for i in range(len(data)):\n",
        "        axes[i].imshow(data[i], aspect='auto', origin='bottom',\n",
        "                       interpolation='none', cmap='inferno')\n",
        "    fig.canvas.draw()\n",
        "    plt.show()\n",
        "\n",
        "def ARPA(text):\n",
        "    out = ''\n",
        "    for word_ in text.split(\" \"):\n",
        "        word=word_; end_chars = ''\n",
        "        while any(elem in word for elem in r\"!?,.;\") and len(word) > 1:\n",
        "            if word[-1] == '!': end_chars = '!' + end_chars; word = word[:-1]\n",
        "            if word[-1] == '?': end_chars = '?' + end_chars; word = word[:-1]\n",
        "            if word[-1] == ',': end_chars = ',' + end_chars; word = word[:-1]\n",
        "            if word[-1] == '.': end_chars = '.' + end_chars; word = word[:-1]\n",
        "            if word[-1] == ';': end_chars = ';' + end_chars; word = word[:-1]\n",
        "            else: break\n",
        "        try: word_arpa = thisdict[word.upper()]\n",
        "        except: word_arpa = ''\n",
        "        if len(word_arpa)!=0: word = \"{\" + str(word_arpa) + \"}\"\n",
        "        out = (out + \" \" + word + end_chars).strip()\n",
        "    if out[-1] != \";\": out = out + \";\"\n",
        "    return out\n",
        "\n",
        "def download_from_google_drive(link, path, quiet=False):\n",
        "    gdown.download(\n",
        "        f'https://drive.google.com/uc?id={link.strip()}', path, quiet=quiet\n",
        "    )\n",
        "\n",
        "locale.getpreferredencoding = getpreferredencoding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C8bbSD03EVq"
      },
      "source": [
        "----------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V20HcqXj2N58"
      },
      "source": [
        "# Krok 3: Ustawienie modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6fpMFkZ8tdy",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#@markdown Jeżeli będzie problem z uprawnieniami do pliku, a są ustawione jak należy, to trzeba trochę poczekać bądź sprawdzić nazwę.\n",
        "#@markdown ### Wymuszone pobieranie modeli\n",
        "#@markdown Po prostu ponownie pobierze zaznaczone modele nawet, jeśli wcześniej były pobrane.\n",
        "pobierz_model_tacotron2 = True #@param{type:'boolean'}\n",
        "pobierz_model_waveglow = True #@param{type:'boolean'}\n",
        "\n",
        "#@markdown ### ID modeli (pobiera je się z linku)\n",
        "#@markdown ID modelu tacotron2:\n",
        "tacotron2_link = \"1df5KQ0WwxllwLsEbp7vdzuqHshhuM5JU\" #@param{type:\"string\"}\n",
        "\n",
        "#@markdown ID modelu waveglow:\n",
        "waveglow_link = \"17xuBnKr6gtGfR21Hmsgx_rk8kKPrEWrn\" #@param{type:\"string\"}\n",
        "tacotron2_pretrained_model = 'tacotron2'\n",
        "\n",
        "if not os.path.exists(tacotron2_pretrained_model) or pobierz_model_tacotron2:\n",
        "    # Pobieranie modelu Tacotron2\n",
        "    download_from_google_drive(tacotron2_link, tacotron2_pretrained_model)\n",
        "\n",
        "waveglow_pretrained_model = 'waveglow'\n",
        "if not os.path.exists(waveglow_pretrained_model) or pobierz_model_waveglow:\n",
        "    # Pobieranie modelu Waveglow\n",
        "    download_from_google_drive(waveglow_link, waveglow_pretrained_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meTH-E481PXT"
      },
      "source": [
        "# Krok 4: Kod syntezy, ukryty by nie zapychał miejsca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJpQFZJy88BM"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#Wstępne przygotowania Tacotrona i Waveglow\n",
        "%matplotlib inline\n",
        "\n",
        "# Download files from Google drive\n",
        "download_from_google_drive('1uciIczSNxzjhWZEzJ_gB2pzLGrtXSQHc', 'merged.dict.txt')\n",
        "download_from_google_drive('1qpgI41wNXFcH-iKq1Y42JlBC9j0je8PW', 'pretrained')\n",
        "download_from_google_drive('1pAB2kQunkDuv6W5fcJiQ0CY8xcJKB22e', 'config.json')\n",
        "\n",
        "thisdict = {}\n",
        "\n",
        "for line in reversed((open('merged.dict.txt', \"r\").read()).splitlines()):\n",
        "    thisdict[(line.split(\" \",1))[0]] = (line.split(\" \",1))[1].strip()\n",
        "\n",
        "#torch.set_grad_enabled(False)\n",
        "\n",
        "# initialize Tacotron2 with the pretrained model\n",
        "hparams = create_hparams()\n",
        "\n",
        "git_clone('https://github.com/patryk025/hifi-gan')\n",
        "\n",
        "try:\n",
        "    os.mkdir(\"test_files\")\n",
        "except FileExistsError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEf8wDNm3Hm9"
      },
      "source": [
        "----------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DygQAcMS1bQC"
      },
      "source": [
        "# Krok 5: Ustawienie parametrów syntezy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkPmpMPx9FIG"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#@markdown **Częstotliwość próbkowania**. Większa częstotliwość próbkowania zwiększa prędkość głosu i jego ton. (domyślnie jest 22050). Lepiej nie zmieniać bazowej wartości.\n",
        "hparams.sampling_rate = 22050 #@param{type:'number', min:'0', max:'384000'}\n",
        "#@markdown **Maksymalna ilość iteracji dekodera** wpływa na długość wygenerowanego głosu.\n",
        "\n",
        "#@markdown Można zwiększyć, by syntezator mógł wygenerować dłuższy głos (domyślnie 1000)\n",
        "hparams.max_decoder_steps = 5000# @param{type:'number',min:1}\n",
        "hparams.gate_threshold = 0.1 # Model must be 90% sure the clip is over before ending generation (the higher this number is, the more likely that the AI will keep generating until it reaches the Max Decoder Steps)\n",
        "model = Tacotron2(hparams)\n",
        "model.load_state_dict(torch.load(tacotron2_pretrained_model)['state_dict'])\n",
        "_ = model.cuda().eval().half()\n",
        "\n",
        "# Załaduj Waveglow\n",
        "waveglow = torch.load(waveglow_pretrained_model)['model']\n",
        "waveglow.cuda().eval().half()\n",
        "for k in waveglow.convinv:\n",
        "    k.float()\n",
        "denoiser = Denoiser(waveglow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWzMtFbl3IWS"
      },
      "source": [
        "----------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPgoGhNT1tWx"
      },
      "source": [
        "# Krok 6: Synteza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEovI0V-Hskt"
      },
      "source": [
        "Od teraz dla zaoszczędzenia miejsca przykładowe teksty można wybrać z wysuwanego menu w inpucie *text*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaQR9z8o9Nc5"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#@markdown **Tekst do odczytania**\n",
        "text = \"Powierzy\\u0142em swoje dziadki dla Antosi i jej Matki. Dzi\\u015B Antosia powidzia\\u0142a, \\u017Ce \\u017Cadnego dzieciaka nie bra\\u0142a wi\\u0119c i nie od da\\u0142a. Co za wredna pa\\u0142a.\" #@param [\"Nam strzelać nie kazano. Wstąpiłem na działo. I spojrzałem na pole. dwieście armat grzmiało. Artyleryji ruskiej ciągną się szeregi. Prosto, długo, daleko, jako morza brzegi.\", \"Wasali przytłoczyło bogactwo i ogrom lądu i nie byli w stanie znaleźć miejsca na wybudowanie ich nowej stolicy.\", \"Korzystanie z dwóch broni oznacza, że nie masz żadnej ochrony i nie możesz blokować. Ale jeśli uderzysz dwiema broniami naraz, wróg może już nie mieć szansy odpowiedzieć.\", \"Z gwiazd obłąkanych, z włosów czesanych, iskry padają, jak z polskiej szabli. widzą je diabli, odpowiadają błyskami. Lecą. świst piór buki ugina.\", \"Jesteś dla mnie jak starszy brat. Nigdy nie miałem starszego brata, ani nawet młodszego. Moi rodzice mnie nie kochali, ale to musiało być dla nich bardzo trudne.\", \"Wiesz... Zabawne jest to, że często jest tak, że najbardziej niebezpieczni okazują się właśnie ci, którzy działają dla wyższych celów.\", \"Niniejszym, w imieniu Aldmerskiego Dominium, na mocy konkordatu bieli i złota, aresztuję meka za wiarę w talosa.\", \"Przed użyciem zapoznaj się z treścią ulotki dołączonej do opakowania bądź skonsultuj się z lekarzem lub farmaceutą, gdyż każdy lek niewłaściwie stosowany zagraża Twojemu życiu lub zdrowiu.\", \"Elektrody otulone są metalowymi prętami otoczonymi sprasowaną otuliną. Dobierane są głównie w zależności od składu chemicznego, właściwości i gabarytów materiałów łączonych, ale także spodziewanej wytrzymałości złącza, rodzaju źródła prądu czy pozycji spawania.\"] {allow-input: true}\n",
        "\n",
        "zagraniczny_głos = False #@param{type:\"boolean\"}\n",
        "denoise_strength =  0.06 #@param{type:\"number\"}\n",
        "equalize = True #@param{type:\"boolean\"}\n",
        "gan = True #@param{type:\"boolean\"}\n",
        "_sigma = 1\n",
        "speed_multiplier = 1\n",
        "raw_input = False\n",
        "\n",
        "\n",
        "polish_letter_pronunciation = [\n",
        "    [\"ch\", \"h\"], [\"Ch\", \"H\"], [\"ó\", \"u\"], [\"x\", \"ks\"], [\"v\", \"w\"], [\"rz\", \"ż\"], [\"Rz\", \"Ż\"], [\"ą \", \"om \"], [\"ą, \", \"om, \"], [\"ą. \", \"om. \"], [\"ą? \", \"om? \"], [\"ą! \", \"om! \"], [\"ą.\", \"om.\"], [\"ąb\", \"omb\"], [\"ąc\", \"onc\"], [\"ąć\", \"onć\"], [\"ąd\", \"ond\"], [\"ąf\", \"onf\"], [\"ąg\", \"ong\"], [\"ąh\", \"onh\"], [\"ąj\", \"onj\"], [\"ąk\", \"onk\"], [\"ąl\", \"oln\"], [\"ął\", \"oł\"], [\"ąm\", \"om\"], [\"ąn\", \"ołn\"], [\"ąp\", \"omp\"], [\"ąs\", \"ons\"], [\"ąś\", \"onś\"], [\"ąt\", \"ont\"], [\"ąw\", \"omw\"], [\"ąz\", \"onz\"], [\"ąż\", \"onż\"], [\"ąź\", \"onź\"], [\"ę \", \"e \"], [\"ęb\", \"enb\"], [\"ęc\", \"enc\"], [\"ęć\", \"enć\"], [\"ęd\", \"end\"], [\"ęg\", \"eng\"], [\"ęk\", \"enk\"], [\"ęl\", \"el\"], [\"ęł\", \"eł\"], [\"ęn\", \"en\"], [\"ęp\", \"emp\"], [\"ęś\", \"enś\"], [\"ęs\", \"ens\"], [\"ęt\", \"ent\"], [\"ęw\", \"emw\"], [\"ęz\", \"enz\"], [\"ęż\", \"enż\"], [\"ęź\", \"enź\"], [\"ę. \", \"e. \"], [\"ę.\", \"e.\"], [\"ę, \", \"e, \"], [\"ę? \", \"e? \"], [\"ę! \", \"e! \"]\n",
        "]\n",
        "\n",
        "files = glob.glob('test_files/*')\n",
        "for f in files:\n",
        "    os.remove(f)\n",
        "\n",
        "if zagraniczny_głos:\n",
        "    for letter, pronunciation in polish_letter_pronunciation:\n",
        "        text = (text.replace(letter, pronunciation))\n",
        "\n",
        "for line in text.split(\"\\n\"):\n",
        "    if len(line) < 1:\n",
        "        continue\n",
        "    print(line)\n",
        "    if raw_input:\n",
        "        if line[-1] != \";\":\n",
        "            line=line+\";\"\n",
        "    else:\n",
        "        line = ARPA(line)\n",
        "    print(line)\n",
        "\n",
        "    sequence = np.array(text_to_sequence(text, ['basic_cleaners']))[None, :]\n",
        "    sequence = torch.autograd.Variable(\n",
        "    torch.from_numpy(sequence)).cuda().long()\n",
        "    mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
        "    with torch.no_grad():\n",
        "        audio = waveglow.infer(mel_outputs_postnet, sigma=_sigma)\n",
        "    audio_denoised = denoiser(audio, strength=denoise_strength)[:, 0]\n",
        "\n",
        "    print(\"Zwykła wersja:\")\n",
        "    ipd.display(ipd.Audio(audio_denoised.cpu().numpy() , rate=hparams.sampling_rate * speed_multiplier))\n",
        "\n",
        "    audio = ipd.Audio(audio_denoised.cpu().numpy(), rate=hparams.sampling_rate * speed_multiplier)\n",
        "    audio = AudioSegment(audio.data[128:], frame_rate=hparams.sampling_rate * speed_multiplier, sample_width=2, channels=1)\n",
        "    audio.export(\"test_files/testnt.wav\", format=\"wav\", bitrate=\"32k\")\n",
        "\n",
        "    !ffmpeg -loglevel quiet -i \"test_files/testnt.wav\" -ss 0.0000 -vcodec copy -acodec copy \"test_files/test.wav\"\n",
        "\n",
        "    if equalize:\n",
        "        !ffmpeg -loglevel quiet -y -i \"test_files/test.wav\" -ac 2 -af \"aresample=44100:resampler=soxr:precision=15, equalizer=f=50:width_type=o:width=0.75:g=3.6, equalizer=f=3000:width_type=o:width=1.0:g=2.0, equalizer=f=10000:width_type=o:width=1.0:g=4.0\" \"test_EQ.wav\"\n",
        "        print(\"Wersja z EQ:\")\n",
        "        ipd.display(ipd.Audio(\"test_EQ.wav\"))\n",
        "\n",
        "    if gan:\n",
        "        if equalize:\n",
        "            print(\"\\n---------Logi generacji GAN---------\\n\")\n",
        "            !python hifi-gan/inference.py --checkpoint_file pretrained\n",
        "            print(\"\\n---------Koniec logów generacji GAN---------\\n\")\n",
        "            print(\"Gan bez EQ:\")\n",
        "            ipd.display(ipd.Audio(\"generated_files/test_generated.wav\"))\n",
        "            !ffmpeg -loglevel quiet -y -i \"generated_files/test_generated.wav\" -ac 2 -af \"aresample=44100:resampler=soxr:precision=15, equalizer=f=50:width_type=o:width=0.75:g=3.6, equalizer=f=3000:width_type=o:width=1.0:g=2.0, equalizer=f=10000:width_type=o:width=1.0:g=4.0\" \"generated_files/test_EQ.wav\"\n",
        "            print(\"Gan z EQ:\")\n",
        "            ipd.display(ipd.Audio(\"generated_files/test_EQ.wav\"))\n",
        "        else:\n",
        "            print(\"\\n---------Logi generacji GAN---------\\n\")\n",
        "            !python hifi-gan/inference.py --checkpoint_file pretrained\n",
        "            print(\"\\n---------Koniec logów generacji GAN---------\\n\")\n",
        "            print(\"Gan bez EQ:\")\n",
        "            ipd.display(ipd.Audio(\"generated_files/test_generated.wav\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwEqXxzr3K87"
      },
      "source": [
        "----------------------------------------------------------------"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}